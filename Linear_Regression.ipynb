{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "bqVZBxrvPD8n",
        "HhfV-JJviCcP",
        "Y3lxredqlCYt",
        "3RnN4peoiCZX",
        "x71ZqKXriCWQ",
        "7hBIi_osiCS2",
        "JlHwYmJAmNHm",
        "35m5QtbWiB9F",
        "PoPl-ycgm1ru",
        "H0kj-8xxnORC",
        "nA9Y7ga8ng1Z",
        "PBTbrJXOngz2",
        "u3PMJOP6ngxN",
        "dauF4eBmngu3",
        "gCX9965dhzqZ",
        "gIfDvo9L0UH2"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ajay-bhise/Linear-Regression-Project/blob/main/Linear_Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    -  **Bike Sharing Demand Prediction**\n",
        "\n"
      ],
      "metadata": {
        "id": "ILM16xV1PD8m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - Regression\n",
        "##### **Contribution**    - Individual\n"
      ],
      "metadata": {
        "id": "bqVZBxrvPD8n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**BUSINESS PROBLEM OVERVIEW**\n",
        "\n",
        "\n",
        "\n",
        "Currently Rental bikes are introduced in many urban cities for the enhancement of mobility comfort. It is important to make the rental bike available and accessible to the public at the right time as it lessens the waiting time. Eventually, providing the city with a stable supply of rental bikes becomes a major concern. The crucial part is the prediction of bike count required at each hour for the stable supply of rental bikes."
      ],
      "metadata": {
        "id": "jivUA-ONOwse"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Know Your Data"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the necessary libraries\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#mount google colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import data from csv to df\n",
        "\n",
        "data_df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Alma Better/Module 4 --- Machine Learning/Linear Regression capstone project - 2/SeoulBikeData.csv',encoding='unicode_escape')"
      ],
      "metadata": {
        "id": "CEhiayUv1809"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First\n",
        "data_df.head()"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns\n",
        "data_df.shape"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Info\n",
        "data_df.info()"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count\n",
        "len(data_df[data_df.duplicated()])"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "print(data_df.isnull().sum())"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What did you know about your dataset?"
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* The above dataset has 8760 rows and 14 columns.\n",
        "* There are no mising values and duplicate values in the dataset."
      ],
      "metadata": {
        "id": "gfoNAAC-nUe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n",
        "## Understanding Your Variables"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns\n",
        "data_df.columns"
      ],
      "metadata": {
        "id": "n87BaXA_42-R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe\n",
        "data_df.describe(include='all')"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables Description"
      ],
      "metadata": {
        "id": "PBTbrJXOngz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "* Date - Date\n",
        "* Hour - Hour of the day (0-23)\n",
        "* Temperature - Temperature of the day\n",
        "* Humidity - Humidity measure\n",
        "* Windspeed - Windspeed\n",
        "* Visibility - Visibility measure\n",
        "* Dew Point Temperature - Dew Point Temperature Measure\n",
        "* Solar Radiation - Solar Radiation Measure\n",
        "* Rainfall - Rainfall in mm\n",
        "* Snowfall - Snowfall measure\n",
        "* Seasons - 1= spring, 2 = summer, 3 = fall, 4 = winter\n",
        "* Holiday - Whether a holiday or not\n",
        "* Functional Day - Whether a functional day or not\n",
        "\n"
      ],
      "metadata": {
        "id": "aJV4KIxSnxay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values for each variable.\n",
        "for i in data_df.columns.tolist():\n",
        "  print(\"No. of unique values in \",i,\"is\",data_df[i].nunique(),\".\")"
      ],
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ***Data Wrangling***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make a copy of data_df so that we can experiment with the data\n",
        "\n",
        "df = data_df.copy()\n",
        "\n",
        "df.shape"
      ],
      "metadata": {
        "id": "GHfcnQ5VY4WH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "id": "3wJ3iG5caGXR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dependent variable 'Rented Bike Count'\n",
        "plt.rcParams[\"figure.figsize\"] = (7,7)\n",
        "sns.distplot(df['Rented Bike Count'],color=\"Blue\")"
      ],
      "metadata": {
        "id": "IQxD5Mh_ZbQu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### This visualization shows that distribution of the dependent variable is right skewed. Applying log transformation would help in making more like a normal/ guassian distribution."
      ],
      "metadata": {
        "id": "uV7OqrancX_i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preparation\n",
        "\n",
        "* Some data points in the dataset are not in the desired fomrat\n",
        "\n",
        "* Date column is not usable unless we extract day, month, year\n",
        "* Seasons column is in the text format - need to do one hot encoding\n",
        "* Holiday columns is in the text format - need to do one hot encoding\n",
        "* same for the functional day column"
      ],
      "metadata": {
        "id": "PXmq1hEVazYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Saperating the Date data into day year months\n",
        "\n",
        "df['parsed_date']=pd.to_datetime(data_df['Date'])\n",
        "\n",
        "#Getting the months and days from date\n",
        "\n",
        "df['month'] = df['parsed_date'].dt.month\n",
        "df['weekday'] = df['parsed_date'].dt.weekday\n",
        "df['year'] = df['parsed_date'].dt.year\n",
        "\n",
        "#drop the date column\n",
        "df.drop(columns=['parsed_date','Date'],axis=1,inplace=True)\n"
      ],
      "metadata": {
        "id": "SdYUuEt9YdXY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "id": "04dbOsosaLEx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Seasons'].unique()"
      ],
      "metadata": {
        "id": "NMH2Q1CvcGAs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['winter'] = np.where(df['Seasons'] == 'Winter',1,0)\n",
        "df['Spring'] = np.where(df['Seasons'] == 'Spring',1,0)\n",
        "df['Summer'] = np.where(df['Seasons'] == 'Summer',1,0)\n",
        "df['Autumn'] = np.where(df['Seasons'] == 'Autumn',1,0)"
      ],
      "metadata": {
        "id": "ybutppSNcOib"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Holiday'].unique()"
      ],
      "metadata": {
        "id": "BCRXRSJldNZV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['is_holiday'] = np.where(df['Holiday'] == 'Holiday',1,0)\n",
        "df['is_not_holiday'] = np.where(df['Holiday'] == 'No Holiday',1,0)\n"
      ],
      "metadata": {
        "id": "sGRknun7dT_4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Functioning Day'].unique()"
      ],
      "metadata": {
        "id": "TDGMYNnydkE6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['is_func_day'] = np.where(df['Functioning Day'] == 'Yes',1,0)\n",
        "df['is_not_func_day'] = np.where(df['Functioning Day'] == 'No',1,0)"
      ],
      "metadata": {
        "id": "s_YteyMXd0fj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns\n",
        "\n",
        "# df.drop(columns=['is_func_day','is_not_func_day'],axis = 1,inplace = True)"
      ],
      "metadata": {
        "id": "-lQS9x97eFWd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Removing the origional columns\n",
        "\n",
        "df.drop(columns  = ['Seasons','Holiday','Functioning Day'],axis = 1,inplace = True)"
      ],
      "metadata": {
        "id": "F79iNS-2e2xV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "id": "c04c21rGfNti"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "QNqkcV8raODX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Visualizations\n",
        "\n",
        "#### In this section we will check following three major points\n",
        "\n",
        "* distribution of variables\n",
        "* multicollinearity of feature variables\n",
        "* relation of each variable with the label"
      ],
      "metadata": {
        "id": "xZK_vbgAfdJb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "id": "J03y6oqwak6A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lets check the relation of each variable with the dependent variable using graphs\n",
        "\n",
        "plt.rcParams['figure.figsize'] = (22, 15)\n",
        "\n",
        "plt.subplot(3,3,1)\n",
        "sns.distplot(df['Temperature(°C)'],color=\"Blue\")\n",
        "plt.title('Temperature(°C)')\n",
        "\n",
        "plt.subplot(3,3,2)\n",
        "sns.distplot(df['Temperature(°C)'],color=\"Blue\")\n",
        "plt.title('Temperature(°C)')\n",
        "\n",
        "plt.subplot(3,3,3)\n",
        "sns.distplot(df['Humidity(%)'],color=\"Blue\")\n",
        "plt.title('Humidity(%)')\n",
        "\n",
        "plt.subplot(3,3,4)\n",
        "sns.distplot(df['Wind speed (m/s)'],color=\"Blue\")\n",
        "plt.title('Wind speed (m/s)')\n",
        "\n",
        "plt.subplot(3,3,5)\n",
        "sns.distplot(df['Visibility (10m)'],color=\"Blue\")\n",
        "plt.title('Visibility (10m)')\n",
        "\n",
        "\n",
        "plt.subplot(3,3,6)\n",
        "sns.distplot(df['Dew point temperature(°C)'],color=\"Blue\")\n",
        "plt.title('Dew point temperature(°C)')\n",
        "\n",
        "plt.subplot(3,3,7)\n",
        "sns.distplot(df['Solar Radiation (MJ/m2)'],color=\"Blue\")\n",
        "plt.title('Solar Radiation (MJ/m2)')\n",
        "\n",
        "plt.subplot(3,3,8)\n",
        "sns.distplot(df['Rainfall(mm)'],color=\"Blue\")\n",
        "plt.title('Rainfall(mm)')\n",
        "\n",
        "plt.subplot(3,3,9)\n",
        "sns.distplot(df['Snowfall (cm)'],color=\"Blue\")\n",
        "plt.title('Snowfall (cm)')\n",
        "\n"
      ],
      "metadata": {
        "id": "9EDr2Yeeku0E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* From above plots we get to know that some of the variable are not normally distributed\n",
        "* To make the distributions normal/Guassian we need to apply log transformation."
      ],
      "metadata": {
        "id": "COuo8wtim51_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "id": "ni5iw3ttnfJE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Checking for multicollinearity"
      ],
      "metadata": {
        "id": "9XWRyf2Ipq5E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_corr = df.corr()\n",
        "sns.heatmap(abs(df_corr), annot=True, cmap='coolwarm')\n"
      ],
      "metadata": {
        "id": "DhcjW0hNp8-z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* calulate VIF to check collinearity"
      ],
      "metadata": {
        "id": "lJblmXxRr7YH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "def calc_vif(X):\n",
        "\n",
        "    # Calculating VIF\n",
        "    vif = pd.DataFrame()\n",
        "    vif[\"variables\"] = X.columns\n",
        "    vif[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
        "\n",
        "    return(vif)"
      ],
      "metadata": {
        "id": "5t8_bhhzsBnP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calc_vif(df[[i for i in df.describe().columns if i not in ['Rented Bike Count']]])"
      ],
      "metadata": {
        "id": "KJ8EArNRsEOg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Observations\n",
        "\n",
        "* There is correlation between Temperature and dew point temperature\n",
        "* We are going to ignore the correlation between the derived variables and origional variables. If our model overfits we can handle it in the regularization.\n"
      ],
      "metadata": {
        "id": "v2PMxTSBqzbu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "NGn6lTSmrZbC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lets check the relation of each variable with the dependent variable using graphs\n",
        "\n",
        "plt.rcParams['figure.figsize'] = (20, 10)\n",
        "\n",
        "plt.subplot(3,3,1)\n",
        "plt.scatter(df['Hour'],df['Rented Bike Count'])\n",
        "plt.title('Hour')\n",
        "\n",
        "plt.subplot(3,3,2)\n",
        "plt.scatter(df['Temperature(°C)'],df['Rented Bike Count'])\n",
        "plt.title('Temperature(°C)')\n",
        "\n",
        "plt.subplot(3,3,3)\n",
        "plt.scatter(df['Humidity(%)'],df['Rented Bike Count'])\n",
        "plt.title('Humidity(%)')\n",
        "\n",
        "plt.subplot(3,3,4)\n",
        "plt.scatter(df['Wind speed (m/s)'],df['Rented Bike Count'])\n",
        "plt.title('Wind speed (m/s)')\n",
        "\n",
        "plt.subplot(3,3,5)\n",
        "plt.scatter(df['Visibility (10m)'],df['Rented Bike Count'])\n",
        "plt.title('Visibility (10m)')\n",
        "\n",
        "\n",
        "plt.subplot(3,3,6)\n",
        "plt.scatter(df['Dew point temperature(°C)'],df['Rented Bike Count'])\n",
        "plt.title('Dew point temperature(°C)')\n",
        "\n",
        "plt.subplot(3,3,7)\n",
        "plt.scatter(df['Solar Radiation (MJ/m2)'],df['Rented Bike Count'])\n",
        "plt.title('Solar Radiation (MJ/m2)')\n",
        "\n",
        "plt.subplot(3,3,8)\n",
        "plt.scatter(df['Rainfall(mm)'],df['Rented Bike Count'])\n",
        "plt.title('Rainfall(mm)')\n",
        "\n",
        "plt.subplot(3,3,9)\n",
        "plt.scatter(df['Snowfall (cm)'],df['Rented Bike Count'])\n",
        "plt.title('T9')\n"
      ],
      "metadata": {
        "id": "EjShXfSOdB_N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lets check the relation of each variable with the dependent variable using graphs\n",
        "\n",
        "plt.rcParams['figure.figsize'] = (20, 10)\n",
        "\n",
        "plt.subplot(3,3,1)\n",
        "plt.scatter(df['month'],df['Rented Bike Count'])\n",
        "plt.title('month')\n",
        "\n",
        "plt.subplot(3,3,2)\n",
        "plt.scatter(df['weekday'],df['Rented Bike Count'])\n",
        "plt.title('weekday')\n",
        "\n",
        "plt.subplot(3,3,3)\n",
        "plt.scatter(df['year'],df['Rented Bike Count'])\n",
        "plt.title('year')\n",
        "\n",
        "plt.subplot(3,3,4)\n",
        "plt.scatter(data_df['Seasons'],df['Rented Bike Count'])\n",
        "plt.title('Seasons')\n",
        "\n",
        "plt.subplot(3,3,5)\n",
        "plt.scatter(data_df['Holiday'],df['Rented Bike Count'])\n",
        "plt.title('Holiday')\n",
        "\n",
        "\n",
        "plt.subplot(3,3,6)\n",
        "plt.scatter(data_df['Functioning Day'],df['Rented Bike Count'])\n",
        "plt.title('Functioning Day')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "rNp_BOQLjCF1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### With scatterplots above, we tried to compare each of the feature variable with the dependent variable.\n",
        "\n",
        "* Temperature, Dew point Temperature, visibility are directly proportional to label.\n",
        "\n",
        "* Windspeed , snowfall , rainfall, sun exposure are somewhat inversrly proportional to label."
      ],
      "metadata": {
        "id": "yI2eTUErmAqa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Implementation"
      ],
      "metadata": {
        "id": "IEh3afwCtXUC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "id": "rC8nxgcZ4hPp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Rented Bike Count'].value_counts()"
      ],
      "metadata": {
        "id": "wb7J6XP_4uW8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# comsidering the observations where Rented Bike Count is non zero\n",
        "temp_df = df[df['Rented Bike Count'] != 0]"
      ],
      "metadata": {
        "id": "uMJX4k5u45TQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Since distribution of the variable mentioned below is skewed, we have taken the log transformation to model the variables\n",
        "\n",
        "temp_df['log_transformed_output'] = temp_df['Rented Bike Count'].apply(lambda x:np.log10(x))\n",
        "temp_df['log_transformed_Visibility'] = temp_df['Visibility (10m)'].apply(lambda x:np.log10(x))\n",
        "temp_df['log_transformed_Wind speed'] = temp_df['Wind speed (m/s)'].apply(lambda x:np.log10(x))\n",
        "temp_df['log_transformed_solar_radiation'] = temp_df['Solar Radiation (MJ/m2)'].apply(lambda x:np.log10(x))\n",
        "temp_df['log_transformed_snowfall'] = temp_df['Snowfall (cm)'].apply(lambda x:np.log10(x))\n",
        "temp_df['log_transformed_rainfall'] = temp_df['Rainfall(mm)'].apply(lambda x:np.log10(x))\n",
        "\n",
        "#replacing the inf values with 0\n",
        "temp_df.replace([np.inf, -np.inf], 0, inplace=True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "X = temp_df[[ 'Hour','Temperature(°C)',\n",
        "       'log_transformed_Wind speed', 'log_transformed_Visibility',\n",
        "       'log_transformed_solar_radiation', 'log_transformed_rainfall', 'log_transformed_snowfall', 'month',\n",
        "       'weekday', 'year', 'winter', 'Spring', 'Summer', 'Autumn', 'is_holiday',\n",
        "       'is_not_holiday', 'is_func_day', 'is_not_func_day']]\n",
        "\n",
        "Y = temp_df[['log_transformed_output']]"
      ],
      "metadata": {
        "id": "1ihN8_jnuJsf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train-Test Split and scaling the variables\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split( X,Y , test_size = 0.1, random_state = 100)\n",
        "\n",
        "std = MinMaxScaler()\n",
        "X_train_std = std.fit_transform(X_train)\n",
        "X_test_std = std.transform(X_test)\n",
        "print(X_train_std.shape)\n",
        "print(X_test_std.shape)"
      ],
      "metadata": {
        "id": "m07wocM8tWiA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Implementing Normal Linear regression\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "reg = LinearRegression().fit(X_train_std, y_train)\n",
        "normal_score = reg.score(X_train_std, y_train)\n",
        "normal_intercept = reg.intercept_\n",
        "coeff = reg.coef_\n",
        "\n",
        "print(\"r2 score fot the model is \",normal_score)\n",
        "print(\"intercept for the emodel is \",normal_intercept)\n",
        "print(\"coeff for the model: \",coeff)"
      ],
      "metadata": {
        "id": "wYukQlrVtVrX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Implementing Lasso regression\n",
        "\n",
        "from sklearn.linear_model import Lasso\n",
        "\n",
        "reg = Lasso(alpha=0.01).fit(X_train_std, y_train)\n",
        "normal_score = reg.score(X_train_std, y_train)\n",
        "normal_intercept = reg.intercept_\n",
        "coeff = reg.coef_\n",
        "\n",
        "print(\"r2 score fot the model is \",normal_score)\n",
        "print(\"intercept for the emodel is \",normal_intercept)\n",
        "print(\"coeff for the model: \",coeff)\n",
        "\n",
        "# In the output we can see some of the parameters went to zero"
      ],
      "metadata": {
        "id": "fRB0RHog1iXq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Implementing Ridge Regression\n",
        "\n",
        "from sklearn.linear_model import Ridge\n",
        "\n",
        "reg = Ridge(alpha=0.01).fit(X_train_std, y_train)\n",
        "\n",
        "normal_score = reg.score(X_train_std, y_train)\n",
        "normal_intercept = reg.intercept_\n",
        "coeff = reg.coef_\n",
        "print(\"r2 score fot the model is \",normal_score)\n",
        "print(\"intercept for the emodel is \",normal_intercept)\n",
        "print(\"coeff for the model: \",coeff)"
      ],
      "metadata": {
        "id": "5hl9_5f-1-F7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import r2_score"
      ],
      "metadata": {
        "id": "6pKDb-1l-I_o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict the valaues for training set to check the trainging set accuracy\n",
        "\n",
        "y_train_ = reg.predict(X_train_std)\n",
        "\n",
        "MSE  = mean_squared_error(10**(y_train), 10**(y_train_))\n",
        "print(\"MSE :\" , MSE)\n",
        "\n",
        "RMSE = np.sqrt(MSE)\n",
        "print(\"RMSE :\" ,RMSE)\n",
        "\n",
        "r2 = r2_score(10**(y_train), 10**(y_train_))\n",
        "print(\"R2 :\" ,r2)\n",
        "print(\"Adjusted R2 : \",1-(1-r2_score(10**(y_train), 10**(y_train_)))*((X_train.shape[0]-1)/(X_train.shape[0]-X_train.shape[1]-1)))\n",
        "\n"
      ],
      "metadata": {
        "id": "DShERI8J9urN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict the valaues for test set to check the trainging set accuracy\n",
        "\n",
        "y_pred = reg.predict(X_test_std)\n",
        "\n",
        "MSE  = mean_squared_error(10**(y_test), 10**(y_pred))\n",
        "# MSE  = mean_squared_error((y_test), (y_pred))\n",
        "print(\"MSE :\" , MSE)\n",
        "\n",
        "RMSE = np.sqrt(MSE)\n",
        "print(\"RMSE :\" ,RMSE)"
      ],
      "metadata": {
        "id": "xpSjkT5iwDbN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "r2 = r2_score(10**(y_test), 10**(y_pred))\n",
        "print(\"R2 :\" ,r2)\n",
        "print(\"Adjusted R2 : \",1-(1-r2_score(10**(y_test), 10**(y_pred)))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)))\n"
      ],
      "metadata": {
        "id": "QOYKk0KRwNWJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Observations\n",
        "\n",
        "* Training set r2 score of normal linear regression and ridge regression is same.\n",
        "* This can be because of train - test split randomness\n",
        "* Implementing cross validation may help."
      ],
      "metadata": {
        "id": "Gd38aIWQyits"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "ridge = Ridge()\n",
        "parameters = {'alpha': [1e-15,1e-13,1e-10,1e-8,1e-5,1e-4,1e-3,1e-2,1e-1,1,5,10,20,30,40,45,50,55,60,100,0.0014]}\n",
        "ridge_regressor = GridSearchCV(ridge, parameters, scoring='neg_mean_squared_error', cv=5)\n",
        "ridge_regressor.fit(X_train_std, y_train)"
      ],
      "metadata": {
        "id": "QquSrZv7yiP-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_cv = ridge_regressor.predict(X_test_std)"
      ],
      "metadata": {
        "id": "R-8fgIwE0Veu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "MSE  = mean_squared_error(10**(y_test), 10**(y_pred_cv))\n",
        "print(\"MSE :\" , MSE)\n",
        "\n",
        "RMSE = np.sqrt(MSE)\n",
        "print(\"RMSE :\" ,RMSE)"
      ],
      "metadata": {
        "id": "SHIWHOMz0qI2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r2 = r2_score(10**(y_test), 10**(y_pred_cv))\n",
        "print(\"R2 :\" ,r2)\n",
        "\n",
        "print(\"Adjusted R2 : \",1-(1-r2_score(10**(y_test), 10**(y_pred_cv)))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)))"
      ],
      "metadata": {
        "id": "tZpKHsy_0xj3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Based on the model coefficient we came to the following conclusions.\n",
        "\n",
        "* Rented Bike count shows positive correlation with temperature. So when the temperature is between 20-30 degree celcius, bike demand will be more.\n",
        "\n",
        "* Rented bike count shows positive relationship with the visibility.\n",
        "\n",
        "* Rental bike count varies inversly wrt rainfall, snowfall and sun irradiation.\n",
        "\n"
      ],
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"
      ],
      "metadata": {
        "id": "gIfDvo9L0UH2"
      }
    }
  ]
}